# -*- coding: utf-8 -*-
"""extract

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yr4ZhdIWUbTd8ARrvEzM5c50-tv3G2o2
"""

# impor library yang dibutuhkan
import time
import requests
import pandas as pd
from bs4 import BeautifulSoup
import re
import time
import datetime

# mengatur user-agent yang akan digunakan untuk menghindari pemblokiran oleh server yang mungkin mendeteksi bot.
HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
        "(KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36"
    )
}

# fungsi mengambil html dari halaman web
def fetching_content(url):
    """Mengambil konten HTML dari URL yang diberikan."""
    session = requests.Session()
    response = session.get(url, headers=HEADERS)
    try:
        response.raise_for_status()
        print(f"Berhasil")
        return response.content
    except requests.exceptions.RequestException as e:
        print(f"Terjadi kesalahan ketika melakukan requests terhadap {url}: {e}")
        return None

def extract_fashion_data(product_soup):
    title_element = product_soup.find('h3', class_='product-title')
    title = title_element.text.strip() if title_element else "Title not found"

    price_container = product_soup.find('div', class_='price-container')
    price = "Price not found"

    if price_container:
        price_tag = price_container.find("span", class_="price")
        price = price_tag.text.strip() if price_tag else "Price not found"
    p_tags = product_soup.find_all("p")

    rating = "Rating not found"
    colors = "Colors not found"
    size = "Size not found"
    gender = "Gender not found"

    for p in p_tags:
        text = p.get_text(strip=True)

        if "Rating" in text:
            match = re.search(r'(\d+(\.\d+)?)', text)
            if match:
                rating = match.group()
            else:
                rating = "Rating not found" # This line should be indented under the 'else'

        elif "Colors" in text:
            match = re.search(r'\d+', text)
            colors = match.group() if match else "Colors not found"

        elif "Size:" in text:
            size = text.split(":", 1)[-1].strip()

        elif "Gender:" in text:
            gender = text.split(":", 1)[-1].strip()

    timestamp = datetime.datetime.now().isoformat()

    fashion = {
        "title": title,
        "price": price,
        "rating": rating,
        "colors": colors,
        "size": size,
        "gender": gender,
        "timestamp": timestamp
    }

    return fashion

def scrape_fashion(start_page=1, max_pages=50, delay=1):
    data = []
    for page_number in range(start_page, max_pages + 1):
        if page_number == 1:
            url = "https://fashion-studio.dicoding.dev/"
        else:
            url = f"https://fashion-studio.dicoding.dev/page{page_number}.html"

        print(f"Scraping halaman: {url}")
        content = fetching_content(url)

        if content:
            soup = BeautifulSoup(content, "html.parser")
            articles_element = soup.find_all('div', class_='collection-card')

            if not articles_element:
                print(f"Tidak ada produk ditemukan di halaman {page_number}, lanjut.")
                continue  # GANTI break ke continue

            for article in articles_element:
                fashion = extract_fashion_data(article)
                data.append(fashion)

            time.sleep(delay)
        else:
            print(f"Gagal mengambil konten dari halaman {page_number}, lanjut.")
            continue
    return data

def main():
    """Fungsi utama untuk keseluruhan proses scraping hingga menyimpannya."""
    all_fashion_data = scrape_fashion()
    df_fashion = pd.DataFrame(all_fashion_data)
    return(df_fashion)

if __name__ == '__main__':
    df_fashion = main()
    print(df_fashion)